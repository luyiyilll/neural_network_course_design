{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            multiple                  36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  20480512  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  65664     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  1290      \n",
      "=================================================================\n",
      "Total params: 20,605,322\n",
      "Trainable params: 20,605,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 709 steps, validate for 1 steps\n",
      "Epoch 1/100\n",
      "709/709 [==============================] - 169s 238ms/step - loss: 2.2644 - accuracy: 0.1534\n",
      "Epoch 2/100\n",
      "709/709 [==============================] - 171s 241ms/step - loss: 2.2349 - accuracy: 0.1734 - val_loss: 2.2715 - val_accuracy: 0.2000\n",
      "Epoch 3/100\n",
      "709/709 [==============================] - 192s 271ms/step - loss: 2.1529 - accuracy: 0.2287\n",
      "Epoch 4/100\n",
      "709/709 [==============================] - 216s 305ms/step - loss: 1.9029 - accuracy: 0.3401 - val_loss: 1.8565 - val_accuracy: 0.3000\n",
      "Epoch 5/100\n",
      "709/709 [==============================] - 215s 303ms/step - loss: 1.5059 - accuracy: 0.4977\n",
      "Epoch 6/100\n",
      "709/709 [==============================] - 197s 278ms/step - loss: 1.1441 - accuracy: 0.6239 - val_loss: 1.0577 - val_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "709/709 [==============================] - 156s 220ms/step - loss: 0.8388 - accuracy: 0.7270\n",
      "Epoch 8/100\n",
      "709/709 [==============================] - 173s 245ms/step - loss: 0.6139 - accuracy: 0.8062 - val_loss: 0.4773 - val_accuracy: 0.9000\n",
      "Epoch 9/100\n",
      "709/709 [==============================] - 158s 223ms/step - loss: 0.4582 - accuracy: 0.8533\n",
      "Epoch 10/100\n",
      "709/709 [==============================] - 152s 215ms/step - loss: 0.3610 - accuracy: 0.8872 - val_loss: 0.3229 - val_accuracy: 0.9000\n",
      "Epoch 11/100\n",
      "709/709 [==============================] - 147s 207ms/step - loss: 0.2896 - accuracy: 0.9099\n",
      "Epoch 12/100\n",
      "709/709 [==============================] - 147s 208ms/step - loss: 0.2284 - accuracy: 0.9286 - val_loss: 0.3921 - val_accuracy: 0.9000\n",
      "Epoch 13/100\n",
      "709/709 [==============================] - 146s 206ms/step - loss: 0.1937 - accuracy: 0.9397\n",
      "Epoch 14/100\n",
      "709/709 [==============================] - 146s 206ms/step - loss: 0.1582 - accuracy: 0.9525 - val_loss: 0.2755 - val_accuracy: 0.9000\n",
      "Epoch 15/100\n",
      "709/709 [==============================] - 144s 203ms/step - loss: 0.1326 - accuracy: 0.9590\n",
      "Epoch 16/100\n",
      "709/709 [==============================] - 143s 202ms/step - loss: 0.1204 - accuracy: 0.9645 - val_loss: 0.0978 - val_accuracy: 0.9000\n",
      "Epoch 17/100\n",
      "709/709 [==============================] - 145s 205ms/step - loss: 0.0990 - accuracy: 0.9704\n",
      "Epoch 18/100\n",
      "709/709 [==============================] - 160s 225ms/step - loss: 0.0908 - accuracy: 0.9725 - val_loss: 0.1529 - val_accuracy: 0.9000\n",
      "Epoch 19/100\n",
      "709/709 [==============================] - 148s 209ms/step - loss: 0.0810 - accuracy: 0.9749\n",
      "Epoch 20/100\n",
      "709/709 [==============================] - 147s 208ms/step - loss: 0.0717 - accuracy: 0.9783 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "709/709 [==============================] - 151s 213ms/step - loss: 0.0641 - accuracy: 0.9809\n",
      "Epoch 22/100\n",
      "709/709 [==============================] - 153s 216ms/step - loss: 0.0623 - accuracy: 0.9807 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "709/709 [==============================] - 155s 218ms/step - loss: 0.0515 - accuracy: 0.9847\n",
      "Epoch 24/100\n",
      "709/709 [==============================] - 150s 212ms/step - loss: 0.0455 - accuracy: 0.9868 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "709/709 [==============================] - 154s 217ms/step - loss: 0.0448 - accuracy: 0.9866\n",
      "Epoch 26/100\n",
      "709/709 [==============================] - 156s 220ms/step - loss: 0.0432 - accuracy: 0.9855 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "709/709 [==============================] - 148s 209ms/step - loss: 0.0345 - accuracy: 0.9899\n",
      "Epoch 28/100\n",
      "709/709 [==============================] - 156s 220ms/step - loss: 0.0384 - accuracy: 0.9884 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "709/709 [==============================] - 158s 222ms/step - loss: 0.0325 - accuracy: 0.9905\n",
      "Epoch 30/100\n",
      "709/709 [==============================] - 154s 217ms/step - loss: 0.0272 - accuracy: 0.9926 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "709/709 [==============================] - 152s 214ms/step - loss: 0.0267 - accuracy: 0.9933\n",
      "Epoch 32/100\n",
      "709/709 [==============================] - 151s 213ms/step - loss: 0.0259 - accuracy: 0.9922 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "709/709 [==============================] - 155s 219ms/step - loss: 0.0257 - accuracy: 0.9918\n",
      "Epoch 34/100\n",
      "709/709 [==============================] - 154s 217ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "709/709 [==============================] - 148s 209ms/step - loss: 0.0229 - accuracy: 0.9936\n",
      "Epoch 36/100\n",
      "709/709 [==============================] - 148s 209ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "709/709 [==============================] - 148s 209ms/step - loss: 0.0188 - accuracy: 0.9945\n",
      "Epoch 38/100\n",
      "709/709 [==============================] - 150s 212ms/step - loss: 0.0154 - accuracy: 0.9959 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "709/709 [==============================] - 148s 208ms/step - loss: 0.0162 - accuracy: 0.9957\n",
      "Epoch 40/100\n",
      "709/709 [==============================] - 149s 210ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "709/709 [==============================] - 151s 213ms/step - loss: 0.0154 - accuracy: 0.9954\n",
      "Epoch 42/100\n",
      "709/709 [==============================] - 148s 209ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 3.9608e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "709/709 [==============================] - 150s 212ms/step - loss: 0.0119 - accuracy: 0.9968\n",
      "Epoch 44/100\n",
      "709/709 [==============================] - 155s 219ms/step - loss: 0.0155 - accuracy: 0.9957 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "709/709 [==============================] - 153s 216ms/step - loss: 0.0111 - accuracy: 0.9971\n",
      "Epoch 46/100\n",
      "709/709 [==============================] - 154s 218ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "709/709 [==============================] - 163s 230ms/step - loss: 0.0120 - accuracy: 0.9969\n",
      "Epoch 48/100\n",
      "709/709 [==============================] - 151s 213ms/step - loss: 0.0132 - accuracy: 0.9965 - val_loss: 6.7361e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "709/709 [==============================] - 185s 261ms/step - loss: 0.0092 - accuracy: 0.9977\n",
      "Epoch 50/100\n",
      "709/709 [==============================] - 175s 246ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 8.4506e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "709/709 [==============================] - 160s 226ms/step - loss: 0.0078 - accuracy: 0.9981\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709/709 [==============================] - 169s 239ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "709/709 [==============================] - 163s 230ms/step - loss: 0.0072 - accuracy: 0.9982\n",
      "Epoch 54/100\n",
      "709/709 [==============================] - 159s 224ms/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 3.1966e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "709/709 [==============================] - 160s 225ms/step - loss: 0.0074 - accuracy: 0.9983\n",
      "Epoch 56/100\n",
      "709/709 [==============================] - 164s 231ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 1.0747e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "709/709 [==============================] - 155s 218ms/step - loss: 0.0078 - accuracy: 0.9984\n",
      "Epoch 58/100\n",
      "709/709 [==============================] - 155s 219ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "709/709 [==============================] - 162s 229ms/step - loss: 0.0050 - accuracy: 0.9996\n",
      "Epoch 60/100\n",
      "709/709 [==============================] - 157s 222ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 6.5815e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "709/709 [==============================] - 157s 222ms/step - loss: 0.0096 - accuracy: 0.9974\n",
      "Epoch 62/100\n",
      "709/709 [==============================] - 160s 225ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 3.4084e-04 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "709/709 [==============================] - 163s 230ms/step - loss: 0.0043 - accuracy: 0.9993\n",
      "Epoch 64/100\n",
      "709/709 [==============================] - 150s 212ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 1.3727e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "709/709 [==============================] - 151s 213ms/step - loss: 0.0059 - accuracy: 0.9983\n",
      "Epoch 66/100\n",
      "709/709 [==============================] - 156s 220ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "709/709 [==============================] - 159s 225ms/step - loss: 0.0080 - accuracy: 0.9977\n",
      "Epoch 68/100\n",
      "709/709 [==============================] - 159s 225ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 6.8409e-04 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "709/709 [==============================] - 161s 228ms/step - loss: 0.0038 - accuracy: 0.9993\n",
      "Epoch 70/100\n",
      "709/709 [==============================] - 165s 233ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 2.0858e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "709/709 [==============================] - 163s 230ms/step - loss: 0.0060 - accuracy: 0.9983\n",
      "Epoch 72/100\n",
      "709/709 [==============================] - 159s 224ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 1.8010e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "709/709 [==============================] - 162s 229ms/step - loss: 0.0039 - accuracy: 0.9992\n",
      "Epoch 74/100\n",
      "709/709 [==============================] - 177s 249ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 1.9505e-04 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "709/709 [==============================] - 172s 242ms/step - loss: 0.0070 - accuracy: 0.9981\n",
      "Epoch 76/100\n",
      "709/709 [==============================] - 165s 233ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 3.0037e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "709/709 [==============================] - 167s 236ms/step - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 78/100\n",
      "709/709 [==============================] - 155s 218ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 1.2236e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "709/709 [==============================] - 154s 217ms/step - loss: 0.0047 - accuracy: 0.9988\n",
      "Epoch 80/100\n",
      "709/709 [==============================] - 153s 216ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 1.0107e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "709/709 [==============================] - 153s 216ms/step - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 82/100\n",
      "709/709 [==============================] - 153s 216ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 2.1480e-05 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "709/709 [==============================] - 153s 216ms/step - loss: 0.0041 - accuracy: 0.9989\n",
      "Epoch 84/100\n",
      "709/709 [==============================] - 153s 216ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 2.8511e-05 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "709/709 [==============================] - 154s 218ms/step - loss: 0.0042 - accuracy: 0.9991\n",
      "Epoch 86/100\n",
      "709/709 [==============================] - 154s 217ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 9.7241e-05 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "709/709 [==============================] - 153s 216ms/step - loss: 0.0017 - accuracy: 0.9999\n",
      "Epoch 88/100\n",
      "709/709 [==============================] - 154s 217ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "709/709 [==============================] - 154s 217ms/step - loss: 0.0028 - accuracy: 0.9996\n",
      "Epoch 90/100\n",
      "709/709 [==============================] - 154s 217ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 3.8464e-05 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "709/709 [==============================] - 162s 229ms/step - loss: 0.0029 - accuracy: 0.9996\n",
      "Epoch 92/100\n",
      "709/709 [==============================] - 165s 233ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 1.0418e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "709/709 [==============================] - 177s 249ms/step - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 94/100\n",
      "709/709 [==============================] - 194s 273ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 3.1157e-05 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "709/709 [==============================] - 192s 271ms/step - loss: 0.0028 - accuracy: 0.9995\n",
      "Epoch 96/100\n",
      "709/709 [==============================] - 197s 278ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 1.4543e-05 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "709/709 [==============================] - 200s 282ms/step - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 98/100\n",
      "709/709 [==============================] - 197s 277ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 8.1425e-05 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "709/709 [==============================] - 186s 262ms/step - loss: 0.0019 - accuracy: 0.9998\n",
      "Epoch 100/100\n",
      "709/709 [==============================] - 192s 270ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 4.8936e-05 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.8936e-05 - accuracy: 1.0000\n",
      "WARNING:tensorflow:From C:\\Users\\LUYI\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: E:\\jupyter\\gesture_recogination\\model\\assets\n",
      "保存模型成功\n",
      "--------------------------------------------------\n",
      "Frozen model layers: \n",
      "x\n",
      "sequential/conv2d/Conv2D/ReadVariableOp/resource\n",
      "sequential/conv2d/Conv2D/ReadVariableOp\n",
      "sequential/conv2d/Conv2D\n",
      "sequential/conv2d/BiasAdd/ReadVariableOp/resource\n",
      "sequential/conv2d/BiasAdd/ReadVariableOp\n",
      "sequential/conv2d/BiasAdd\n",
      "sequential/conv2d/Relu\n",
      "sequential/max_pooling2d/MaxPool\n",
      "sequential/conv2d_1/Conv2D/ReadVariableOp/resource\n",
      "sequential/conv2d_1/Conv2D/ReadVariableOp\n",
      "sequential/conv2d_1/Conv2D\n",
      "sequential/conv2d_1/BiasAdd/ReadVariableOp/resource\n",
      "sequential/conv2d_1/BiasAdd/ReadVariableOp\n",
      "sequential/conv2d_1/BiasAdd\n",
      "sequential/conv2d_1/Relu\n",
      "sequential/max_pooling2d_1/MaxPool\n",
      "sequential/conv2d_2/Conv2D/ReadVariableOp/resource\n",
      "sequential/conv2d_2/Conv2D/ReadVariableOp\n",
      "sequential/conv2d_2/Conv2D\n",
      "sequential/conv2d_2/BiasAdd/ReadVariableOp/resource\n",
      "sequential/conv2d_2/BiasAdd/ReadVariableOp\n",
      "sequential/conv2d_2/BiasAdd\n",
      "sequential/conv2d_2/Relu\n",
      "sequential/flatten/Const\n",
      "sequential/flatten/Reshape\n",
      "sequential/dense/MatMul/ReadVariableOp/resource\n",
      "sequential/dense/MatMul/ReadVariableOp\n",
      "sequential/dense/MatMul\n",
      "sequential/dense/BiasAdd/ReadVariableOp/resource\n",
      "sequential/dense/BiasAdd/ReadVariableOp\n",
      "sequential/dense/BiasAdd\n",
      "sequential/dense/Relu\n",
      "sequential/dropout/Identity\n",
      "sequential/dense_1/MatMul/ReadVariableOp/resource\n",
      "sequential/dense_1/MatMul/ReadVariableOp\n",
      "sequential/dense_1/MatMul\n",
      "sequential/dense_1/BiasAdd/ReadVariableOp/resource\n",
      "sequential/dense_1/BiasAdd/ReadVariableOp\n",
      "sequential/dense_1/BiasAdd\n",
      "sequential/dense_1/Relu\n",
      "sequential/dense_2/MatMul/ReadVariableOp/resource\n",
      "sequential/dense_2/MatMul/ReadVariableOp\n",
      "sequential/dense_2/MatMul\n",
      "sequential/dense_2/BiasAdd/ReadVariableOp/resource\n",
      "sequential/dense_2/BiasAdd/ReadVariableOp\n",
      "sequential/dense_2/BiasAdd\n",
      "Identity\n",
      "--------------------------------------------------\n",
      "Frozen model inputs: \n",
      "[<tf.Tensor 'x:0' shape=(None, 100, 100, 3) dtype=float32>]\n",
      "Frozen model outputs: \n",
      "[<tf.Tensor 'Identity:0' shape=(None, 10) dtype=float32>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型转换完成，训练结束\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets,layers,optimizers,Sequential,metrics\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "import os \n",
    "import pathlib\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "\n",
    "\n",
    "def read_data(path):\n",
    "    path_root = pathlib.Path(path)\n",
    "    # print(path_root)\n",
    "    # for item in path_root.iterdir():\n",
    "    #     print(item)\n",
    "    image_paths = list(path_root.glob('*/*'))\n",
    "    image_paths = [str(path) for path in image_paths]\n",
    "    random.shuffle(image_paths)\n",
    "    image_count = len(image_paths)\n",
    "    # print(image_count)\n",
    "    # print(image_paths[:10])\n",
    "\n",
    "    label_names = sorted(item.name for item in path_root.glob('*/') if item.is_dir())\n",
    "    # print(label_names)\n",
    "    label_name_index = dict((name, index) for index, name in enumerate(label_names))\n",
    "    # print(label_name_index)\n",
    "    image_labels = [label_name_index[pathlib.Path(path).parent.name] for path in image_paths]\n",
    "    # print(\"First 10 labels indices: \", image_labels[:10])\n",
    "    return image_paths,image_labels,image_count\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [100, 100])\n",
    "    image /= 255.0  # normalize to [0,1] range\n",
    "    # image = tf.reshape(image,[100*100*3])\n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_image(path,label):\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image),label\n",
    "\n",
    "def creat_dataset(image_paths,image_labels,bitch_size):\n",
    "    db = tf.data.Dataset.from_tensor_slices((image_paths, image_labels))\n",
    "    dataset = db.map(load_and_preprocess_image).batch(bitch_size)    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def train_model(train_data,test_data):\n",
    "    #构建模型\n",
    "    network = keras.Sequential([\n",
    "            keras.layers.Conv2D(32,kernel_size=[5,5],padding=\"same\",activation=tf.nn.relu),\n",
    "            keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "            keras.layers.Conv2D(64,kernel_size=[3,3],padding=\"same\",activation=tf.nn.relu),\n",
    "            keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "            keras.layers.Conv2D(64,kernel_size=[3,3],padding=\"same\",activation=tf.nn.relu),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(512,activation='relu'),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Dense(128,activation='relu'),\n",
    "            keras.layers.Dense(10)])\n",
    "    network.build(input_shape=(None,100,100,3))\n",
    "    network.summary()\n",
    "\n",
    "    network.compile(optimizer=optimizers.SGD(lr=0.001),\n",
    "            loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy']\n",
    "    )\n",
    "    #模型训练\n",
    "    network.fit(train_data, epochs = 100,validation_data=test_data,validation_freq=2)  \n",
    "    network.evaluate(test_data)\n",
    "\n",
    "    tf.saved_model.save(network,'./model/')\n",
    "    print(\"保存模型成功\")\n",
    "\n",
    "\n",
    "\n",
    "    # Convert Keras model to ConcreteFunction\n",
    "    full_model = tf.function(lambda x: network(x))\n",
    "    full_model = full_model.get_concrete_function(\n",
    "    tf.TensorSpec(network.inputs[0].shape, network.inputs[0].dtype))\n",
    "\n",
    "    # Get frozen ConcreteFunction\n",
    "    frozen_func = convert_variables_to_constants_v2(full_model)\n",
    "    frozen_func.graph.as_graph_def()\n",
    "\n",
    "    layers = [op.name for op in frozen_func.graph.get_operations()]\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Frozen model layers: \")\n",
    "    for layer in layers:\n",
    "        print(layer)\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Frozen model inputs: \")\n",
    "    print(frozen_func.inputs)\n",
    "    print(\"Frozen model outputs: \")\n",
    "    print(frozen_func.outputs)\n",
    "\n",
    "    # Save frozen graph from frozen ConcreteFunction to hard drive\n",
    "    tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n",
    "            logdir=\"./model/frozen_model/\",\n",
    "            name=\"frozen_graph.pb\",\n",
    "            as_text=False)\n",
    "    print(\"模型转换完成，训练结束\")\n",
    "\n",
    "\n",
    "if  __name__ == \"__main__\":\n",
    "    print(tf.__version__)\n",
    "    train_path = './Dataset'\n",
    "#     train_path = 'D:\\\\code\\\\PYTHON\\\\gesture_recognition\\\\Dataset'\n",
    "    test_path = './testdata' \n",
    "    image_paths,image_labels,_ = read_data(train_path)\n",
    "    train_data = creat_dataset(image_paths,image_labels,16)\n",
    "    image_paths,image_labels,_ = read_data(test_path)\n",
    "    test_data = creat_dataset(image_paths,image_labels,16)\n",
    "    train_model(train_data,test_data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
